{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rollout_dir = \"~/persistent/rollouts/deepseek_r1_7b_gh_patches_2k_fixed_reward/train\"\n",
    "df = pd.read_json(\"~/persistent/rollouts/deepseek_r1_7b_gh_patches_2k_fixed_reward/train/77.jsonl\", lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "# Get all JSONL files in the directory\n",
    "jsonl_files = sorted(glob.glob(os.path.join(os.path.expanduser(train_rollout_dir), \"*.jsonl\")))\n",
    "\n",
    "# Filter to every 10th file\n",
    "every_10th_files = jsonl_files[::10]\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(len(every_10th_files), 1, figsize=(12, 3*len(every_10th_files)))\n",
    "if len(every_10th_files) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "# Plot histogram for each file\n",
    "for i, file_path in enumerate(every_10th_files):\n",
    "    # Read the JSONL file\n",
    "    df = pd.read_json(file_path, lines=True)\n",
    "    \n",
    "    # Calculate mean and median\n",
    "    mean_score = df['score'].mean()\n",
    "    median_score = df['score'].median()\n",
    "    \n",
    "    # Create histogram\n",
    "    axes[i].hist(df['score'], bins=30, alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    # Add vertical lines for mean and median\n",
    "    axes[i].axvline(mean_score, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_score:.3f}')\n",
    "    axes[i].axvline(median_score, color='green', linestyle='-', linewidth=2, label=f'Median: {median_score:.3f}')\n",
    "    \n",
    "    axes[i].set_title(f'Score Distribution - {os.path.basename(file_path)}')\n",
    "    axes[i].set_xlabel('Score')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the files being plotted\n",
    "print(f\"Plotted {len(every_10th_files)} files:\")\n",
    "for file_path in every_10th_files:\n",
    "    print(f\"  {os.path.basename(file_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count perfect scores (score = 1.0) in each JSONL file\n",
    "print(\"Perfect scores (score = 1.0) per JSONL file:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for file_path in jsonl_files:\n",
    "    df = pd.read_json(file_path, lines=True)\n",
    "    perfect_scores = (df['score'] == 1.0).sum()\n",
    "    total_samples = len(df)\n",
    "    percentage = (perfect_scores / total_samples) * 100 if total_samples > 0 else 0\n",
    "    \n",
    "    print(f\"{os.path.basename(file_path)}:\")\n",
    "    print(f\"  Perfect scores: {perfect_scores}/{total_samples} ({percentage:.2f}%)\")\n",
    "    print()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"Summary:\")\n",
    "print(\"=\" * 20)\n",
    "all_perfect_scores = []\n",
    "all_total_samples = []\n",
    "\n",
    "for file_path in jsonl_files:\n",
    "    df = pd.read_json(file_path, lines=True)\n",
    "    perfect_scores = (df['score'] == 1.0).sum()\n",
    "    total_samples = len(df)\n",
    "    all_perfect_scores.append(perfect_scores)\n",
    "    all_total_samples.append(total_samples)\n",
    "\n",
    "total_perfect = sum(all_perfect_scores)\n",
    "total_samples = sum(all_total_samples)\n",
    "overall_percentage = (total_perfect / total_samples) * 100 if total_samples > 0 else 0\n",
    "\n",
    "print(f\"Total perfect scores across all files: {total_perfect}/{total_samples} ({overall_percentage:.2f}%)\")\n",
    "print(f\"Average perfect scores per file: {np.mean(all_perfect_scores):.2f}\")\n",
    "print(f\"Min perfect scores in a file: {min(all_perfect_scores)}\")\n",
    "print(f\"Max perfect scores in a file: {max(all_perfect_scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with all rollouts that have perfect scores (score = 1.0)\n",
    "perfect_rollouts = []\n",
    "\n",
    "for file_path in jsonl_files:\n",
    "    df = pd.read_json(file_path, lines=True)\n",
    "    # Filter for perfect scores\n",
    "    perfect_df = df[df['score'] == 1.0].copy()\n",
    "    # Add source file information\n",
    "    perfect_df['source_file'] = os.path.basename(file_path)\n",
    "    perfect_rollouts.append(perfect_df)\n",
    "\n",
    "# Combine all perfect rollouts into one dataframe\n",
    "if perfect_rollouts:\n",
    "    all_perfect_rollouts = pd.concat(perfect_rollouts, ignore_index=True)\n",
    "    print(f\"Found {len(all_perfect_rollouts)} rollouts with perfect scores\")\n",
    "    print(f\"Shape of perfect rollouts dataframe: {all_perfect_rollouts.shape}\")\n",
    "    print(\"\\nFirst few perfect rollouts:\")\n",
    "    print(all_perfect_rollouts.head())\n",
    "else:\n",
    "    print(\"No perfect rollouts found\")\n",
    "    all_perfect_rollouts = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_perfect_rollouts[\"output\"][30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
